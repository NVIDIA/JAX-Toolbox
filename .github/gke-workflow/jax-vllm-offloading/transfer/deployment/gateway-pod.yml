apiVersion: v1
kind: Pod
metadata:
  name: jax-vllm-gateway
  namespace: default
  labels:
    app: jax-vllm-gateway
spec:
  imagePullSecrets:
  - name: jax-toolbox-ghcr
  containers:
  - name: jax-vllm-gateway-server
    image: ghcr.io/nvidia/jax-toolbox-internal:19461214142-jio-amd64
    workingDir: /opt/jtbx/jax-inference-offloading
    command: ["python", "jax_inference_offloading/controller/gateway.py"]
    volumeMounts:
    - mountPath: /dev/shm
      name: shmem
    env:
    - name: GATEWAY_PORT
      value: "50051"
    ports:
    - containerPort: 50051

  volumes:
    - name: output
      emptyDir: {}
    - name: shmem
      emptyDir:
        medium: Memory

  # schedule on GPU node (but don't request GPU resource)
  tolerations:
  - key: "nvidia.com/gpu"
    operator: "Exists"
    effect: "NoSchedule"

        
