# syntax=docker/dockerfile:1-labs
ARG BASE_IMAGE=ghcr.io/nvidia/jax-toolbox:base
ARG DEST_MANIFEST_DIR=/opt/manifest.d
ARG SRC_PATH_JAX=/opt/jax
ARG SRC_PATH_XLA=/opt/xla
ARG SRC_PATH_FLAX=/opt/flax
ARG SRC_PATH_TE=/opt/transformer-engine
ARG GIT_USER_NAME="JAX Toolbox"
ARG GIT_USER_EMAIL=jax@nvidia.com

ARG BAZEL_CACHE=/tmp
ARG BUILD_DATE

###############################################################################
## Build JAX
###############################################################################

FROM ${BASE_IMAGE} as builder
ARG DEST_MANIFEST_DIR
ARG SRC_PATH_JAX
ARG SRC_PATH_XLA
ARG BAZEL_CACHE
ARG GIT_USER_NAME
ARG GIT_USER_EMAIL

ADD --chmod=777 create-distribution.sh ${DEST_MANIFEST_DIR}/

RUN get-source.sh -l jax -m ${MANIFEST_FILE}
RUN --mount=type=ssh \
    --mount=type=secret,id=SSH_KNOWN_HOSTS,target=/root/.ssh/known_hosts \
    get-source.sh -l xla -m ${MANIFEST_FILE}

ADD build-jax.sh local_cuda_arch test-jax.sh /usr/local/bin/
# TODO: move this patch into the manifest
ADD xla-arm64-neon.patch /opt
RUN build-jax.sh \
    --bazel-cache ${BAZEL_CACHE} \
    --src-path-jax ${SRC_PATH_JAX} \
    --src-path-xla ${SRC_PATH_XLA} \
    --sm all \
    --xla-arm64-patch /opt/xla-arm64-neon.patch \ 
    --clean

###############################################################################
## Pack jaxlib wheel and various source dirs into a pre-installation image
###############################################################################

ARG BASE_IMAGE
FROM ${BASE_IMAGE} as mealkit
ARG DEST_MANIFEST_DIR
ARG SRC_PATH_JAX
ARG SRC_PATH_XLA
ARG SRC_PATH_TE
ARG BUILD_DATE

ENV BUILD_DATE=${BUILD_DATE}
# The following environment variables tune performance
# TODO: --xla_gpu_enable_xla_runtime_executable=true should be removed ASAP. It is a WAR for a crash observed in the default runtime leading to this error message: "nccl_all_reduce_thunk.cc:175] Check failed: reduction_kind.has_value()"
ENV XLA_FLAGS="--xla_gpu_enable_latency_hiding_scheduler=true --xla_gpu_enable_async_all_gather=true --xla_gpu_enable_async_reduce_scatter=true --xla_gpu_enable_triton_gemm=false --xla_gpu_enable_xla_runtime_executable=true"
ENV CUDA_DEVICE_MAX_CONNECTIONS=1
ENV NCCL_IB_SL=1
ENV NCCL_NVLS_ENABLE=0
ENV CUDA_MODULE_LOADING=EAGER

ADD --chmod=777 create-distribution.sh ${DEST_MANIFEST_DIR}/

COPY --from=builder ${SRC_PATH_JAX} ${SRC_PATH_JAX}
COPY --from=builder ${SRC_PATH_XLA} ${SRC_PATH_XLA}
ADD build-jax.sh local_cuda_arch test-jax.sh /usr/local/bin/

RUN mkdir -p /opt/pip-tools.d
RUN <<"EOF" bash -ex
# Encourage a newer numpy so that pip's dependency resolver will allow newer
# versions of other packages that rely on newer numpy, but also include fixes
# for compatibility with newer JAX versions. e.g. chex.
echo "numpy >= 1.24.1"                                  >> /opt/pip-tools.d/requirements-jax.in
echo "-e file://${SRC_PATH_JAX}"                        >> /opt/pip-tools.d/requirements-jax.in
echo "jaxlib @ file://$(ls ${SRC_PATH_JAX}/dist/*.whl)" >> /opt/pip-tools.d/requirements-jax.in
EOF

## Flax
RUN get-source.sh -l flax -m ${MANIFEST_FILE} -o /opt/pip-tools.d/requirements-flax.in

## Transformer engine: check out source and build wheel
ENV NVTE_FRAMEWORK=jax
ENV SRC_PATH_TE=${SRC_PATH_TE}
RUN <<"EOF" bash -ex -o pipefail
pip install ninja && rm -rf ~/.cache/pip
get-source.sh -l transformer-engine -m ${MANIFEST_FILE}
pushd ${SRC_PATH_TE}
python setup.py bdist_wheel && rm -rf build
echo "transformer-engine @ file://$(ls ${SRC_PATH_TE}/dist/*.whl)" >> /opt/pip-tools.d/requirements-te.in
EOF

# TODO: properly configure entrypoint

###############################################################################
## Install primary packages and transitive dependencies
###############################################################################

FROM mealkit as final

RUN pip-finalize.sh

