name: ~test TransformerEngine

on:
  workflow_call:
    inputs:
      TE_IMAGE:
        type: string
        description: 'JAX+TE+PAXML image'
        required: true
        default: 'ghcr.io/nvidia/upstream-pax:latest'
      ARTIFACT_NAME:
        type: string
        description: 'Name of the artifact zip file'
        required: false
        default: 'artifact-te'
      BADGE_FILENAME:
        type: string
        description: 'Name of the endpoint JSON file for shields.io badge'
        required: false
        default: 'badge-te'

jobs:
  te-unit-tests:
    runs-on: [self-hosted, V100]
    env:
      ARTIFACT_NAME_FULL: ${{ inputs.ARTIFACT_NAME }}-unit-test
      BADGE_FILENAME_FULL: ${{ inputs.BADGE_FILENAME }}-unit-test.json
    steps:
      - name: Print environment variables
        run: env

      - name: Print GPU information
        run: nvidia-smi

      - name: Login to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.repository_owner }}
          password: ${{ secrets.GITHUB_TOKEN }}
          
      - name: Check out the repository under ${GITHUB_WORKSPACE}
        uses: actions/checkout@v4
        
      - name: Pull TE image
        shell: bash -x -e {0}
        run: |
          docker pull ${{ inputs.TE_IMAGE }}
          docker tag ${{ inputs.TE_IMAGE }} te:local

      - name: Run TE unit tests with docker
        shell: docker run --gpus all -v {0}:/cmd.sh -v /log:/log te:local bash -x /cmd.sh
        run: |
          pip install pytest-reportlog
          pytest --report-log=/log/report.jsonl ${SRC_PATH_TE}/tests/jax

      - name: Generate sitrep
        if: success() || failure()
        shell: bash -x -e {0}
        run: |
          # bring in utility functions
          source .github/workflows/scripts/to_json.sh

          badge_label='TE Unit test'
          failed_tests=$(cat /log/report.jsonl | grep -c 'failed' || true)
          passed_tests=$(cat /log/report.jsonl | grep -c 'passed' || true)
          total_tests=$((failed_tests + passed_tests))
          
          if [[ ${errors} > 0 ]] || [[ ${total_tests} == 0 ]]; then
            badge_message='error'
            badge_color=red
            summary='TE Unit test did not complete due to errors.'
          else
            badge_message="${passed_tests}/${total_tests} passed"
            if [[ ${failed_tests} == 0 ]]; then
              badge_color=brightgreen
            else
              badge_color=yellow
            fi
            summary="TE Unit test: $badge_message"
          fi
          echo "failed tests: " $failed_tests " passed tests: " $passed_tests " total_tests: " $total_tests " summary: " $summary
          to_json \
            summary \
            errors total_tests passed_tests failed_tests \
            badge_label badge_color badge_message \
          > sitrep.json

          schemaVersion=1 \
          label="${badge_label}" \
          message="${badge_message}" \
          color="${badge_color}" \
          to_json schemaVersion label message color \
          > ${{ env.BADGE_FILENAME_FULL }}

      - name: Upload unit test json logs
        if: success() || failure()
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.ARTIFACT_NAME_FULL }}
          path: |
            /log/report.jsonl
            sitrep.json
            ${{ env.BADGE_FILENAME_FULL }}

  te-multi-gpu:
    strategy:
      matrix:
        N_GPU: [2, 4, 8]
      fail-fast: false
    uses: ./.github/workflows/_test_slurm_pyxis.yaml
    secrets:
      SSH_PRIVATE_KEY: ${{ secrets.SSH_PRIVATE_KEY }}
      SLURM_LOGIN_USER: ${{ secrets.CLUSTER_LOGIN_USER }}
      CONTAINER_REGISTRY_TOKEN: ${{ secrets.github_token }}
    with:
      NAME: te-${{ matrix.N_GPU }}GPU
      ARTIFACT_NAME: ${{ inputs.ARTIFACT_NAME }}-${{ matrix.N_GPU }}GPU
      SLURM_LOGIN_HOSTNAME: ${{ vars.HOSTNAME_SLURM_LOGIN }}
      SLURM_SCRATCH_PATH: /nfs/cluster
      NODES: 1
      GPUS_PER_NODE: ${{ matrix.N_GPU }}
      NTASKS: 1
      NTASKS_PER_NODE: 1
      TIME_LIMIT: '00:10:00'
      EXTRA_EXPORTS: 'VOCAB_PATH=gs://t5-data/vocabs/cc_all.32000.100extra/sentencepiece.model'
      IMAGE: ghcr.io/nvidia/jax:upstream-pax
      SRUN_PREAMBLE: |
        nvidia-smi
        pip install \
          pytest \
          pytest-reportlog \
          cuda-python \
          -r ${SRC_PATH_TE}/examples/jax/encoder/requirements.txt
      SRUN_SCRIPT: |
        set -ex
        cd ${SRC_PATH_TE}/examples/jax/encoder
        pytest --report-log=/output/pytest.jsonl \
          test_single_gpu_encoder.py \
          test_multigpu_encoder.py \
          test_model_parallel_encoder.py

  sitrep:
    needs: te-multi-gpu
    if: success() || failure()
    runs-on: ubuntu-latest
    steps:
      - name: Check out the repository under ${GITHUB_WORKSPACE}
        uses: actions/checkout@v4

      - name: Download artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts/
          pattern: ${{ inputs.ARTIFACT_NAME }}-*
          merge-multiple: true

      - name: Generate sitrep
        shell: bash -x -e {0}
        run: |
          ls -lR artifacts/
      #     # bring in utility functions
      #     source .github/workflows/scripts/to_json.sh

      #     EXIT_STATUSES="output/*-status.json"
      #     badge_label='TE Multi GPU tests'
      #     passed_tests=$(jq -r '. | select ((.state == "COMPLETED") and (.exitcode == "0")) | .state' $EXIT_STATUSES | wc -l)
      #     failed_tests=$(jq -r '. | select ((.state != "COMPLETED") or (.exitcode != "0")) | .state' $EXIT_STATUSES | wc -l)
      #     total_tests=$(ls $EXIT_STATUSES | wc -l)
          
      #     if [[ ${failed_tests} > 0 ]] || [[ ${total_tests} == 0 ]]; then
      #       badge_message='error'
      #       badge_color=red
      #       summary='TE multi GPU tests did not complete due to errors.'
      #     else
      #       badge_message="${passed_tests}/${total_tests} passed"
      #       if [[ ${failed_tests} == 0 ]]; then
      #         badge_color=brightgreen
      #       else
      #         badge_color=yellow
      #       fi
      #       summary="TE multi GPU tests : $badge_message"
      #     fi

      #     to_json \
      #       summary \
      #       total_tests passed_tests failed_tests \
      #       badge_label badge_color badge_message \
      #     > sitrep.json

      #     schemaVersion=1 \
      #     label="${badge_label}" \
      #     message="${badge_message}" \
      #     color="${badge_color}" \
      #     to_json schemaVersion label message color \
      #     > ${{ env.BADGE_FILENAME_FULL }}
          
      # - name: Upload training logs as artifacts
      #   uses: actions/upload-artifact@v4
      #   with:
      #     name: ${{ env.ARTIFACT_NAME_FULL }}
      #     path: |
      #       output/
      #       sitrep.json
      #       ${{ env.BADGE_FILENAME_FULL }}
