name: ~test, unit

on:
  workflow_call:
    inputs:
      IMAGE:
        type: string
        description: 'Test image built by NVIDIA/JAX-Toolbox'
        required: true
      TEST_NAME:
        type: string
        description: 'Library to run unit tests on SLURM for'
        required: true
      EXECUTE:
        type: string
        description: 'Test command to run in the container'
        required: false
      STATISTICS_SCRIPT:
        type: string
        description: 'Script to compile the test statistics to report in badge file'
        required: false
      ARTIFACTS:
        type: string
        description: 'Test artifacts to collect'
        required: false

jobs:
  runner:
    uses: ./.github/workflows/_runner_ondemand_slurm.yaml
    with:
      NAME: "A100"
      LABELS: "A100,${{ github.run_id }}"
      TIME: "01:00:00"
    secrets: inherit

  run-unit-test:
    strategy:
      fail-fast: false
      matrix:
        GPU_ARCH: [V100, A100]
        include:
          - EXTRA_LABEL: "self-hosted"
          # ensures A100 job lands on dedicated runner for this particular job
          - GPU_ARCH: A100
            EXTRA_LABEL: "${{ github.run_id }}"
    name: ${{ inputs.TEST_NAME }}-${{ matrix.GPU_ARCH }}-unit-test
    runs-on: 
      - self-hosted
      - "${{ matrix.GPU_ARCH }}"
      - "${{ matrix.EXTRA_LABEL }}"
    env:
      ARTIFACT_NAME_FULL: ${{ inputs.TEST_NAME }}-unit-test-${{ matrix.GPU_ARCH }}
      BADGE_FILENAME_FULL: badge-${{ inputs.TEST_NAME }}-unit-test-${{ matrix.GPU_ARCH }}.json
    steps:
      - name: Print environment variables
        run: env

      - name: Print GPU information
        run: nvidia-smi  

      - name: Check out repository
        uses: actions/checkout@v4

      - name: Login to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.repository_owner }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Run tests
        shell: bash -x -e {0}
        continue-on-error: true
        run: |
          ${{ inputs.EXECUTE }}

      - name: Calculate test statistics
        id: test-stats
        shell: bash -x -e {0}
        continue-on-error: true
        run: |
          ${{ inputs.STATISTICS_SCRIPT }}

      - name: Summarize test statistics
        id: summary
        shell: bash -x -e {0}
        run: |
          # bring in utility functions
          source .github/workflows/scripts/to_json.sh

          total_tests=${{ steps.test-stats.outputs.TOTAL_TESTS }}
          errors=${{ steps.test-stats.outputs.ERRORS }}
          failed_tests=${{ steps.test-stats.outputs.FAILED_TESTS }}
          passed_tests=${{ steps.test-stats.outputs.PASSED_TESTS }}

          if [[ ${errors} > 0 ]] || [[ ${total_tests} == 0 ]]; then
            echo "badge_color='red'" >> $GITHUB_OUTPUT
            echo "badge_message='error'" >> $GITHUB_OUTPUT
            echo "summary='${{ inputs.TEST_NAME }} unit test on ${{ matrix.GPU_ARCH }} did not complete due to errors.'" >> $GITHUB_OUTPUT
            exit 1
          else
            if [[ ${failed_tests} == 0 ]]; then
              echo "badge_color='brightgreen'" >> $GITHUB_OUTPUT
            else
              echo "badge_color='yellow'" >> $GITHUB_OUTPUT
            fi
            echo "badge_message='${passed_tests}/${total_tests} passed'" >> $GITHUB_OUTPUT
            echo "summary='${{ inputs.TEST_NAME }} unit test on ${{ matrix.GPU_ARCH }}: ${total_tests} total tests, ${error} errors, ${passed_tests} passed, ${failed_tests} failed.'" >> $GITHUB_OUTPUT
          fi

      - name: Generate sitrep
        id: sitrep
        if: "!cancelled()"
        shell: bash -x -e {0}
        run: |
          badge_label='${{ inputs.TEST_NAME }} ${{ matrix.GPU_ARCH }} Unit'

          total_tests=${{ steps.test-stats.outputs.TOTAL_TESTS }} \
          errors=${{ steps.test-stats.outputs.ERRORS }} \
          failed_tests=${{ steps.test-stats.outputs.FAILED_TESTS }} \
          passed_tests=${{ steps.test-stats.outputs.PASSED_TESTS }} \
          summary="${{ steps.summary.outputs.summary }}" \
          badge_message="${{ steps.summary.outputs.badge_message }}" \
          badge_color="${{ steps.summary.outputs.badge_color }}" \
          to_json \
            summary \
            errors total_tests passed_tests failed_tests \
            badge_label badge_color badge_message \
          > sitrep.json

          schemaVersion=1 \
          label="${badge_label}" \
          message="${{ steps.summary.outputs.badge_message }}" \
          color="${{ steps.summary.outputs.badge_color }}" \
          to_json schemaVersion label message color \
          > ${{ env.BADGE_FILENAME_FULL }}

      - name: Upload artifacts
        if: "!cancelled()"
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.ARTIFACT_NAME_FULL }}
          path: |
            sitrep.json
            ${{ env.BADGE_FILENAME_FULL }}
            ${{ inputs.ARTIFACTS }}
