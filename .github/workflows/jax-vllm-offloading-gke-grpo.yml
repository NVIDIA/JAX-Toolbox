name: JAX-vLLM offloading GRPO (GKE, XPK)

on:
  workflow_call:
    inputs:
      JAX_VLLM_OFFLOADING_IMAGE:
        type: string
        description: MaxText image from ghcr.io/nvidia
        default: ghcr.io/nvidia/jax-toolbox-internal:19461214142-jio-amd64
        required: false

jobs:
  jax-vllm-offloading-grpo-gke-xpk:
    runs-on: gke-a3mega
    strategy:
      matrix:
        model: ["meta-llama/Llama-3.1-8B-Instruct", "meta-llama/Llama-3.1-70B-Instruct"]
    env:
      WORKLOAD_NAME_PREFIX: gke-jax-vllm-grpo
      JAX_VLLM_OFFLOADING_IMAGE: ${{ inputs.JAX_VLLM_OFFLOADING_IMAGE }}
      
      NUM_NODES: 2
      ENV_FILE: ../../.github/gke-workflow/jax-vllm-offloading/transfer/jobset.env

    steps:
    - uses: actions/checkout@v4

    - name: Login to GitHub Container Registry
      uses: docker/login-action@v3
      with:
        registry: ghcr.io
        username: ${{ github.repository_owner }}
        password: ${{ secrets.GITHUB_TOKEN }}

    - name: K8s GHCR store and delete token
      id: store-token
      uses: ./.github/actions/store-delete-k8s-ghcr

    - name: Run XPK workload on cluster
      uses: ./.github/actions/gke-xpk
      with:
        IMAGE: ${{ env.JAX_VLLM_OFFLOADING_IMAGE }}
        IMAGE_PULL_SECRET_NAME: ${{ steps.store-token.outputs.token-name }}
        WORKLOAD_NAME_PREFIX: ${{ env.WORKLOAD_NAME_PREFIX }}
        ENV_FILE: ${{ env.ENV_FILE }}
        COMMAND: |
          set -x;
          export LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu:/usr/local/cuda-12.9/compat/lib.real:/usr/local/nvidia/lib64;
          export MODEL_NAME=${{ matrix.model }}
          env;

          pip install jax[k8s];
          python -c 'import jax; jax.distributed.initialize(); print(jax.devices()); print(jax.local_devices()); assert jax.process_count() > 1; assert len(jax.devices()) > len(jax.local_devices());';

          PIDS=();
          if [ \${NODE_RANK} = 0 ]; then
            echo Starting gateway;
            cd /opt/jtbx/jax-inference-offloading;
            python jax_inference_offloading/controller/gateway.py 2>&1 | tee -a gateway.log &
            PIDS+=(\$!);

            echo Starting rollout;
            cd /opt/jtbx/jax-inference-offloading/examples;
            python rollout.py 2>&1 | tee -a rollout.log &
            PIDS+=(\$!);
          else
            echo Starting trainer;
            python trainer.py 2>&1 | tee -a trainer.log &
            PIDS+=(\$!);
          fi;

          wait \${PIDS[@]};
          EXIT_CODE=\$PIPESTATUS;
