name: "~Sandbox"

on:
  workflow_dispatch:

jobs:
  sandbox:
    env:
      IMAGE_NAME: ghcr.io/nvidia/jax-toolbox-internal:10352352914-maxtext-amd64
    uses: ./.github/workflows/_test_unit.yaml
    with:
      TEST_NAME: nsys-jax
      EXECUTE: |
        # Test cases:
        # - 1 GPU, profiled from the beginning
        # - 1 GPU, with targeted collection that's too short
        # - 1 GPU, with targeted collection that's sufficient
        # - multi-GPU
        # in principle all of them with/without analysis recipes,
        # but probably not worth actually doing that
        NSYS_JAX="docker run --shm-size=1g --gpus all ${IMAGE_NAME} nsys-jax"
        ${NSYS_JAX} --nsys-jax-analysis summary test-maxtext.sh |& tee full-execution.log
        num_failures=$(($? != 0))
        ${NSYS_JAX} --nsys-jax-analysis summary \
          --capture-range=cudaProfilerApi \
          --capture-range-end=stop -- \
          --sample=none \
          test-maxtext.sh \
          --additional-args "profiler=nsys skip_first_n_steps_for_profiler=4 profiler_steps=5" \
          --steps 10 |& tee partial-execution.log
        num_failures=$((num_failures + ($? != 0)))
        ls -R .
        exit $num_failures
      STATISTICS_SCRIPT: |
        # errors=$(cat test-*.log | grep -c 'ERROR:' || true)
        # failed_tests=$(cat test-*.log | grep -c 'FAILED in' || true)
        # passed_tests=$(cat test-*.log | grep -c 'PASSED in' || true)
        # total_tests=$((failed_tests + passed_tests))
        # echo "TOTAL_TESTS=${total_tests}" >> $GITHUB_OUTPUT
        # echo "ERRORS=${errors}" >> $GITHUB_OUTPUT
        # echo "PASSED_TESTS=${passed_tests}" >> $GITHUB_OUTPUT
        # echo "FAILED_TESTS=${failed_tests}" >> $GITHUB_OUTPUT
        echo "TOTAL_TESTS=3" >> $GITHUB_OUTPUT
        echo "ERRORS=1" >> $GITHUB_OUTPUT
        echo "PASSED_TESTS=1" >> $GITHUB_OUTPUT
        echo "FAILED_TESTS=1" >> $GITHUB_OUTPUT
      ARTIFACTS: |
        full-execution.log
        partial-execution.log
    secrets: inherit
