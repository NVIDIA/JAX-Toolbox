name: ~test T5X, MGMN

on:
  workflow_call:
    inputs:
      T5X_IMAGE:
        type: string
        description: T5X image from ghcr.io/nvidia/t5x
        default: 'ghcr.io/nvidia/t5x:latest'
        required: false
      BATCH_SIZE_PER_GPU:
        type: number
        description: Batch size per GPU
        default: 32
        required: false

jobs:

  single-process-multi-device:
    strategy:
      matrix:
        N_GPU: [1, 2, 4, 8]
      fail-fast: false

    runs-on: ubuntu-22.04

    steps:
      - name: Print environment variables
        run: env

      - name: Setup SSH agent
        uses: webfactory/ssh-agent@v0.8.0
        with:
          ssh-private-key: ${{ secrets.SSH_PRIVATE_KEY }}

      - name: Add known SSH host
        shell: bash -x -e {0}
        run: |
          echo "150.230.212.101 ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDcOJt0Q0qYfShF03/rFPYpq+muMHBIfMlvitzEsSm4onWkG4YU0NBvG5WKcU2dLoMdhCIy+SQYtDeNm9Lj5GIqsLSsVMBSAurIMAzyiJU3DuahiWQGMa3rOVEFzgRtmo58202Ijw61WwVi47OvzJL72Oy2RO8hqVvU0ojcQo1jiQxtj39u1Be7dzIXJHLs7xdpI7V8mGxwQ1dgcjcXSh43br9V24pAebK2abGD8KRZ1H0YDgyaYek0ub5AHAeeznL/FUs0lud1xicABd5qo+w1PyIA+1A+TkRTrbHCBtc2w9w3zaO4p+Yi/ITTjhtnPTAmTD7U+km2mhiR+dLbx15D" >> ~/.ssh/known_hosts
          echo "165.1.79.135 ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQC+/i0SQXfIUF/GVFFw4XbjPObOuI5Xe7ZYS8fxYtQGXVBnaGs+2qYpmNS2GNoMhAc/w6+uP0gNJcVj0TXNWtSJgXgagO6zVqD4xGSqNOU82PsqRiJvVzjA4nTcGrBdIzh6sLwgkjuGKKjF5XhCJ6BQwPH/GLS9b16eewi3Ppmxp1SKca2sXIUPLrCOpZ4RY/hiQm9vTUfmOWuijxQcbOGWtc6ghV1IJpyCZGtvakhr/nR1LFQmDdbJ7MtKyqmoBbeiEQmlht2a7FGVQY8KTZsVSpYUUHT2zwGLBqogRlaxbv3ANavklG06ZpQJtpf300nr6Ix1UpAedhVpuJVGVJR9kyGZHrll60tjTMzy5Kq3RmxjmF9b524Ig8gMmwIi1G+sU5+OUSzVNGzeuvAhSOwKbFLFq9n8nPdBYGh2MDSm4aIv3Zl/YmyM4Ts2OdKF/BWyqUaGtgz38zUWEbZ2QvnebiTGcBkjBC4b8yMCjTubIFanjUNOFWz4E6GWW5enh5c=" >> ~/.ssh/known_hosts

      - name: Labels and metadata
        id: meta
        shell: bash -x -e {0}
        run: |
          IMAGE="$(echo ${{inputs.T5X_IMAGE}} | sed 's/\//#/')"
          TEST_CASE_NAME=1P${{ matrix.N_GPU }}G
          JOB_NAME=${GITHUB_RUN_ID}-${TEST_CASE_NAME}
          LOG_FILE=/nfs/cluster/${JOB_NAME}.log
          MODEL_PATH=/nfs/cluster/${JOB_NAME}
          BATCH_SIZE=$((${{ inputs.BATCH_SIZE_PER_GPU }} * ${{ matrix.N_GPU }}))
          for var in IMAGE TEST_CASE_NAME JOB_NAME LOG_FILE MODEL_PATH BATCH_SIZE; do
            echo "$var=${!var}" >> $GITHUB_OUTPUT
          done

      - name: Submit SLURM jobs over SSH
        id: submit
        shell: bash -O expand_aliases -x -e {0}
        run: |
          alias sshx='ssh -o "ServerAliveInterval 7" ${{ secrets.CLUSTER_LOGIN_USER }}@${{ secrets.CLUSTER_LOGIN_IP }}'
          sshx "date && hostname && sinfo"          
          sshx mkdir -p ${{ steps.meta.outputs.MODEL_PATH }}
          JOB=$(sshx sbatch --parsable << EOF
          #!/bin/bash
          #SBATCH --job-name=${{ steps.meta.outputs.JOB_NAME }}
          #SBATCH --exclusive
          #SBATCH --nodes=1
          #SBATCH --tasks=1
          #SBATCH --gpus-per-node=${{ matrix.N_GPU }}
          #SBATCH --time=00:30:00
          #SBATCH --output=${{ steps.meta.outputs.LOG_FILE }}
          #SBATCH --export="ENROOT_PASSWORD=${{ secrets.GITHUB_TOKEN }},NVCR_TOKEN=$${{ secrets.NVCR_TOKEN }}"
          time srun \
            --container-image=${{ steps.meta.outputs.IMAGE }} \
            --container-mounts=${{ steps.meta.outputs.MODEL_PATH }}:/output \
            --container-entrypoint \
            test-t5x.sh \
              --output /output/${{ steps.meta.outputs.TEST_CASE_NAME }} \
              --dtype bfloat16 \
              --batch-size ${{ steps.meta.outputs.BATCH_SIZE }} \
              --epochs 7 \
              --steps-per-epoch 100
          EOF
          )

          set +x
          while sshx squeue -j $JOB | grep -q $JOB; do
            echo "SLURM Job $JOB is still running."
            sleep 15
          done
          echo "SLRUM Job $JOB finished."
          set -x

      - name: Retrieve training logs and upload to TensorBoard server
        shell: bash -x -e {0}
        run: |
          mkdir output/
          rsync -rtz --progress \
            ${{ secrets.CLUSTER_LOGIN_USER }}@${{ secrets.CLUSTER_LOGIN_IP }}:${{ steps.meta.outputs.LOG_FILE }} \
            output/${{ steps.meta.outputs.TEST_CASE_NAME }}.log
          rsync -rtz --progress \
            ${{ secrets.CLUSTER_LOGIN_USER }}@${{ secrets.CLUSTER_LOGIN_IP }}:${{ steps.meta.outputs.MODEL_PATH }}/* \
            output/
          rsync -rtz --progress \
            output/* \
            ${{ secrets.TENSORBOARD_UPLOAD_USER }}@${{ vars.TENSORBOARD_SERVER_IP }}:/tensorboard-logs/${GITHUB_RUN_ID}

      - name: Upload training logs as artifacts
        uses: actions/upload-artifact@v3
        with:
          name: ${{ steps.meta.outputs.JOB_NAME }}
          path: output/*

  multi-gpu-multi-node:
    strategy:
      matrix:
        N_GPU: [1, 2, 4, 8]
        N_NODE: [1, 2]
      fail-fast: false

    runs-on: ubuntu-22.04

    steps:
      - name: Print environment variables
        run: env

      - name: Setup SSH agent
        uses: webfactory/ssh-agent@v0.8.0
        with:
          ssh-private-key: ${{ secrets.SSH_PRIVATE_KEY }}

      - name: Add known SSH host
        shell: bash -x -e {0}
        run: |
          echo "150.230.212.101 ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDcOJt0Q0qYfShF03/rFPYpq+muMHBIfMlvitzEsSm4onWkG4YU0NBvG5WKcU2dLoMdhCIy+SQYtDeNm9Lj5GIqsLSsVMBSAurIMAzyiJU3DuahiWQGMa3rOVEFzgRtmo58202Ijw61WwVi47OvzJL72Oy2RO8hqVvU0ojcQo1jiQxtj39u1Be7dzIXJHLs7xdpI7V8mGxwQ1dgcjcXSh43br9V24pAebK2abGD8KRZ1H0YDgyaYek0ub5AHAeeznL/FUs0lud1xicABd5qo+w1PyIA+1A+TkRTrbHCBtc2w9w3zaO4p+Yi/ITTjhtnPTAmTD7U+km2mhiR+dLbx15D" >> ~/.ssh/known_hosts
          echo "165.1.79.135 ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQC+/i0SQXfIUF/GVFFw4XbjPObOuI5Xe7ZYS8fxYtQGXVBnaGs+2qYpmNS2GNoMhAc/w6+uP0gNJcVj0TXNWtSJgXgagO6zVqD4xGSqNOU82PsqRiJvVzjA4nTcGrBdIzh6sLwgkjuGKKjF5XhCJ6BQwPH/GLS9b16eewi3Ppmxp1SKca2sXIUPLrCOpZ4RY/hiQm9vTUfmOWuijxQcbOGWtc6ghV1IJpyCZGtvakhr/nR1LFQmDdbJ7MtKyqmoBbeiEQmlht2a7FGVQY8KTZsVSpYUUHT2zwGLBqogRlaxbv3ANavklG06ZpQJtpf300nr6Ix1UpAedhVpuJVGVJR9kyGZHrll60tjTMzy5Kq3RmxjmF9b524Ig8gMmwIi1G+sU5+OUSzVNGzeuvAhSOwKbFLFq9n8nPdBYGh2MDSm4aIv3Zl/YmyM4Ts2OdKF/BWyqUaGtgz38zUWEbZ2QvnebiTGcBkjBC4b8yMCjTubIFanjUNOFWz4E6GWW5enh5c=" >> ~/.ssh/known_hosts

      - name: Labels and metadata
        id: meta
        shell: bash -x -e {0}
        run: |
          IMAGE="$(echo ${{inputs.T5X_IMAGE}} | sed 's/\//#/')"
          TEST_CASE_NAME=${{ matrix.N_GPU }}G${{ matrix.N_NODE }}N
          TOTAL_TASKS=$((${{ matrix.N_GPU }} * ${{ matrix.N_NODE }}))
          JOB_NAME=${GITHUB_RUN_ID}-${TEST_CASE_NAME}
          LOG_FILE=/nfs/cluster/${JOB_NAME}.log
          MODEL_PATH=/nfs/cluster/${JOB_NAME}
          BATCH_SIZE=$((${{ inputs.BATCH_SIZE_PER_GPU }} * ${{ matrix.N_GPU }} * ${{ matrix.N_NODE }}))
          for var in IMAGE TEST_CASE_NAME TOTAL_TASKS JOB_NAME LOG_FILE MODEL_PATH BATCH_SIZE; do
            echo "$var=${!var}" >> $GITHUB_OUTPUT
          done

      - name: Submit SLURM jobs over SSH
        id: submit
        shell: bash -O expand_aliases -x -e {0}
        run: |
          alias sshx='ssh -o "ServerAliveInterval 7" ${{ secrets.CLUSTER_LOGIN_USER }}@${{ secrets.CLUSTER_LOGIN_IP }}'
          sshx "date && hostname && sinfo"          
          sshx mkdir -p ${{ steps.meta.outputs.MODEL_PATH }}
          JOB=$(sshx sbatch --parsable << EOF
          #!/bin/bash
          #SBATCH --job-name=${{ steps.meta.outputs.JOB_NAME }}
          #SBATCH --exclusive
          #SBATCH --nodes=${{ matrix.N_NODE }}
          #SBATCH --gpus-per-node=${{ matrix.N_GPU }}
          #SBATCH --tasks=${{ steps.meta.outputs.TOTAL_TASKS }}
          #SBATCH --tasks-per-node=${{ matrix.N_GPU }}
          #SBATCH --time=00:30:00
          #SBATCH --output=${{ steps.meta.outputs.LOG_FILE }}
          #SBATCH --export="ENROOT_PASSWORD=${{ secrets.GITHUB_TOKEN }},NVCR_TOKEN=$${{ secrets.NVCR_TOKEN }}"
          time srun \
            --container-image=${{ steps.meta.outputs.IMAGE }} \
            --container-mounts=${{ steps.meta.outputs.MODEL_PATH }}:/output \
            --container-entrypoint \
            test-t5x.sh \
              --output /output/${{ steps.meta.outputs.TEST_CASE_NAME }} \
              --dtype bfloat16 \
              --batch-size ${{ steps.meta.outputs.BATCH_SIZE }} \
              --epochs 7 \
              --steps-per-epoch 100 \
              --multiprocess
          EOF
          )

          set +x
          while sshx squeue -j $JOB | grep -q $JOB; do
            echo "SLURM Job $JOB is still running."
            sleep 15
          done
          echo "SLRUM Job $JOB finished."
          set -x

      - name: Retrieve training logs and upload to TensorBoard server
        shell: bash -x -e {0}
        run: |
          mkdir output/
          rsync -rtz --progress \
            ${{ secrets.CLUSTER_LOGIN_USER }}@${{ secrets.CLUSTER_LOGIN_IP }}:${{ steps.meta.outputs.LOG_FILE }} \
            output/${{ steps.meta.outputs.TEST_CASE_NAME }}.log
          rsync -rtz --progress \
            ${{ secrets.CLUSTER_LOGIN_USER }}@${{ secrets.CLUSTER_LOGIN_IP }}:${{ steps.meta.outputs.MODEL_PATH }}/* \
            output/
          rsync -rtz --progress \
            output/* \
            ${{ secrets.TENSORBOARD_UPLOAD_USER }}@${{ vars.TENSORBOARD_SERVER_IP }}:/tensorboard-logs/${GITHUB_RUN_ID}

      - name: Upload training logs as artifacts
        uses: actions/upload-artifact@v3
        with:
          name: ${{ steps.meta.outputs.JOB_NAME }}
          path: output/*

  summary:
    runs-on: ubuntu-22.04

    steps:
      - name: Generate TensorBoard query URL
        run: |
          echo "[view metrics](http://${{ vars.TENSORBOARD_SERVER_IP }}:6006/#scalars&regexInput=${GITHUB_RUN_ID}&_smoothingWeight=0&tagFilter=seqs_per)" >> $GITHUB_STEP_SUMMARY