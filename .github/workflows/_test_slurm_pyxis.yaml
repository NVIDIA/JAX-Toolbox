name: ~test multi-node jobs via SLURM+Pyxis

on:
  workflow_call:
    secrets:
      SSH_PRIVATE_KEY:
        required: true
        description: SSH private key for accessing the SLURM login node
      SLURM_LOGIN_USER:
        required: true
        description: Username for the SLURM login node
      CONTAINER_REGISTRY_TOKEN:
        required: true
        description: Token for accessing the container registry
    inputs:
      NAME:
        type: string
        description: Name of the test case and output artifact tarball
        required: true
      SLURM_LOGIN_HOSTNAME:
        type: string
        description: Hostname of the SLURM login node
        required: true
      OUTPUT_BASEDIR:
        type: string
        description: Base directory for the SLURM scratch space
        required: true
      OUTPUT_MOUNTPOINT:
        type: string
        description: Mountpoint for the SLURM scratch space in the enroot container
        required: true
      NODES:
        type: number
        description: Number of nodes to request
        required: true
      GPUS_PER_NODE:
        type: number
        description: Number of GPUs per node to request
        required: true
      NTASKS:
        type: number
        description: Number of tasks to run
        required: true
      NTASKS_PER_NODE:
        type: number
        description: Number of tasks per node to run
        required: true
      TIME_LIMIT:
        type: string
        description: Time limit for the job
        required: true
      EXTRA_EXPORTS:
        type: string
        description: Comma-separated list of extra environment variables to export to the SLURM job
        required: false
      IMAGE:
        type: string
        description: Image from ghcr.io/nvidia
        required: true
      SRUN_PREAMBLE:
        type: string
        description: Content of the script to be run on the compute nodes in the enroot container using a single task before the main script
        required: false
        default: 'true'
      SRUN_SCRIPT:
        type: string
        description: Content of the script to be run on the compute nodes in the enroot container
        required: true
    outputs:
      SLURM_JOB_ID:
        description: ID of the SLURM job
        value: ${{ jobs.run-test.outputs.SLURM_JOB_ID }}
      SLURM_STATE:
        description: State of the SLURM job
        value: ${{ jobs.run-test.outputs.SLURM_STATE }}
      SLURM_EXITCODE:
        description: Exit code of the SLURM job
        value: ${{ jobs.run-test.outputs.SLURM_EXITCODE }}

jobs:

  run-test:
    name: ${{ inputs.NAME }}
    runs-on: jumpbox
    outputs:
      SLURM_JOB_ID: ${{ steps.submit.outputs.SLURM_JOB_ID }}
      SLURM_STATE: ${{ steps.exit-info.outputs.SLURM_STATE }}
      SLURM_EXITCODE: ${{ steps.exit-info.outputs.SLURM_EXITCODE }}
    steps:
      - name: Print environment variables
        run: env

      - name: Check out the repository under ${GITHUB_WORKSPACE}
        uses: actions/checkout@v4

      - name: Setup SSH
        id: setup-ssh
        uses: ./.github/actions/setup-ssh
        with:
          ssh-private-key: ${{ secrets.SSH_PRIVATE_KEY }}
          ssh-known-hosts: ${{ vars.SSH_KNOWN_HOSTS }}
          
      - name: Labels and metadata
        id: meta
        shell: bash -x -e {0}
        run: |
          IMAGE="$(echo ${{inputs.IMAGE}} | sed 's/\//#/')"
          OUTPUT_PATH=${{ inputs.OUTPUT_BASEDIR }}/${{ github.run_id }}/${{ inputs.NAME }}
          LOG_FILE=${{ inputs.OUTPUT_BASEDIR }}/${{ github.run_id }}/${{ inputs.NAME }}.log
          for var in IMAGE LOG_FILE OUTPUT_PATH; do
            echo "$var=${!var}" >> $GITHUB_OUTPUT
          done
          
      - name: Submit SLURM jobs over SSH
        id: submit
        uses: ./.github/actions/submit-slurm-job
        with: |
            image: ${{ steps.meta.outputs.IMAGE }}
            log_file: ${{ steps.meta.outputs.LOG_FILE }}
            output_path: ${{ steps.meta.outputs.OUTPUT_PATH }}
            time_limit: ${{ inputs.TIME_LIMIT }}
            nodes: ${{ inputs.NODES }}
            gpus_per_node: ${{ inputs.GPUS_PER_NODE }}
            ntasks: ${{ inputs.NTASKS }}
            ntasks_per_node: ${{ inputs.NTASKS_PER_NODE }}
            extra_exports: ${{ inputs.EXTRA_EXPORTS }}
            srun_preamble: ${{ inputs.SRUN_PREAMBLE }}
            srun_script: ${{ inputs.SRUN_SCRIPT }}
            slurm_login_user: ${{ secrets.SLURM_LOGIN_USER }}
            slurm_login_hostname: ${{ inputs.SLURM_LOGIN_HOSTNAME }}
            container_registry_token: ${{ secrets.CONTAINER_REGISTRY_TOKEN }}
            output_mountpoint: ${{ inputs.OUTPUT_MOUNTPOINT }}

      - name: Wait for SLURM job to complete
        id: wait
        uses: ./.github/actions/wait-slurm-job
        with: |
          host: ${{ secrets.SLURM_LOGIN_USER }}@${{ inputs.SLURM_LOGIN_HOSTNAME }}
          job_id: ${{ steps.submit.outputs.SLURM_JOB_ID }}

      - name: Query for job exit info
        id: exit-info
        uses: ./.github/actions/query-slurm-job
        with: |
          slurm_login_user: ${{ secrets.SLURM_LOGIN_USER }}
          slurm_login_hostname: ${{ inputs.SLURM_LOGIN_HOSTNAME }}
          job_id: ${{ steps.submit.outputs.SLURM_JOB_ID }}
          log_file: ${{ steps.meta.outputs.LOG_FILE }}

      - name: Gather artifacts
        if: "!cancelled()"
        shell: bash -x -e {0}
        run: |
          function rsync-down() {
            rsync -rtz --progress ${{ secrets.SLURM_LOGIN_USER }}@${{ inputs.SLURM_LOGIN_HOSTNAME }}:$1 $2
          }
          mkdir -p artifacts/
          rsync-down ${{ steps.meta.outputs.LOG_FILE }} artifacts/
          mkdir -p artifacts/output
          rsync-down ${{ steps.meta.outputs.OUTPUT_PATH }}/* artifacts/output/

      - name: Write sitrep status
        if: "!cancelled()"
        shell: bash -x -e {0}
        run: |
          . .github/workflows/scripts/to_json.sh

          run_id=${{ github.run_id }} \
          slurm_job_id=${{ steps.submit.outputs.SLURM_JOB_ID }} \
          slurm_state=${{ steps.exit-info.outputs.SLURM_STATE }} \
          slurm_exitcode=${{ steps.exit-info.outputs.SLURM_EXITCODE }} \
          to_json run_id slurm_job_id slurm_state slurm_exitcode \
          > artifacts/sitrep.json

      - name: Upload training logs as artifacts
        if: "!cancelled()"
        uses: actions/upload-artifact@v4
        with:
          name: ${{ inputs.NAME }}
          path: artifacts/*

      - name: Remove orphaned SLURM job if the CI job is cancelled or finished
        if: always() && steps.exit-info.outputs.SLURM_EXITCODE != 0
        shell: bash -x -e {0}
        run: |
          ssh ${{ secrets.SLURM_LOGIN_USER }}@${{ inputs.SLURM_LOGIN_HOSTNAME }} \
            scancel ${{ steps.submit.outputs.SLURM_JOB_ID }}
