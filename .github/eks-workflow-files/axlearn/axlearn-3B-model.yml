apiVersion: batch/v1
kind: Job
metadata:
  name: PLACEHOLDER
  labels:
    kueue.x-k8s.io/queue-name: p5-queue
spec:
  # the job will run for 20 mins, as we can't set max_steps
  activeDeadlineSeconds: 1200
  completions: 1
  parallelism: 1
  template:
    spec:
      restartPolicy: Never
      containers:
      - name: axlearn-fuji-3B
        image: PLACEHOLDER
        command:
          - bash
          - -xo
          - pipefail
          - -c
          - |        

            BASEDIR="/opt/axlearn"
            CONFIG="fuji-3B-v3-flash-single-host"
            BASE_XLA_FLAGS=${BASE_XLA_FLAGS:---xla_gpu_enable_latency_hiding_scheduler=true
                 --xla_gpu_enable_highest_priority_async_stream=true
                 --xla_gpu_all_reduce_combine_threshold_bytes=1073741824
                 --xla_gpu_all_gather_combine_threshold_bytes=1073741824
                 --xla_gpu_reduce_scatter_combine_threshold_bytes=1073741824
                 --xla_gpu_enable_pipelined_all_gather=true
                 --xla_gpu_enable_pipelined_reduce_scatter=true
                 --xla_gpu_enable_pipelined_all_reduce=true
                 --xla_gpu_enable_while_loop_double_buffering=true
                 --xla_gpu_enable_triton_gemm=false
                 --xla_gpu_enable_all_gather_combine_by_dim=false
                 --xla_gpu_enable_reduce_scatter_combine_by_dim=false
                 --xla_disable_hlo_passes=rematerialization}

            export XLA_FLAGS="$BASE_XLA_FLAGS ${XLA_FLAGS:-}" 
            
            LOG_DIR=${BASEDIR}/logs
            TRAINER_DIR=${LOG_DIR}/${CONFIG}${POSTFIX}-eks/trainer-dir
            mkdir -p ${TRAINER_DIR}

            cat << EOF > tf_gpu_fix.py
            import tensorflow as tf
            tf.config.set_visible_devices([], 'GPU')
            import runpy
            runpy.run_module('axlearn.common.launch_trainer_main', run_name='__main__')
            EOF

            python3 tf_gpu_fix.py  \
               --module=text.gpt.c4_trainer \
                --config=${CONFIG} \
                --trainer_dir=${TRAINER_DIR} \
                --data_dir=gs://axlearn-public/tensorflow_datasets \
                --jax_backend=gpu 

        resources:
          limits:
            nvidia.com/gpu: 8
        volumeMounts:
        - name: output
          mountPath: /opt/output
      imagePullSecrets:
      - name: PLACEHOLDER  
      volumes:
      - name: output
        emptyDir: {}
