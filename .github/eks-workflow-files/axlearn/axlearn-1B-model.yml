apiVersion: batch/v1
kind: Job
metadata:
  name: PLACEHOLDER
  labels:
    kueue.x-k8s.io/queue-name: p5-queue
spec:
  # the job will run for 20 mins, as we can' tset max_steps
  activeDeadlineSeconds: 1200
  completions: 1
  parallelism: 1
  template:
    spec:
      restartPolicy: Never
      containers:
      - name: axlearn
        image: PLACEHOLDER
        command:
          - bash
          - -xo
          - pipefail
          - -c
          - |        

            BASEDIR="/opt/axlearn"
            CONFIG="fuji-1B-v3-flash-single-host"
            HLO_DUMP=0
            POSTFIX=""

            AR_THRESHOLD=1073741824
            AG_THRESHOLD=8589934592
            RS_THRESHOLD=8589934592
            XLA_BASE_FLAGS="--xla_gpu_enable_latency_hiding_scheduler=true
                            --xla_gpu_enable_triton_gemm=false
                            --xla_gpu_enable_highest_priority_async_stream=true
                            --xla_gpu_all_gather_combine_threshold_bytes=${AG_THRESHOLD}
                            --xla_gpu_reduce_scatter_combine_threshold_bytes=${RS_THRESHOLD}
                            --xla_gpu_enable_pipelined_all_gather=true
                            --xla_gpu_enable_pipelined_reduce_scatter=true
                            --xla_gpu_enable_nccl_comm_splitting=false"

            export XLA_PYTHON_CLIENT_PREALLOCATE=false
            export TF_GPU_ALLOCATOR=cuda_malloc_async
            export XLA_FLAGS="${XLA_BASE_FLAGS}"

            export NCCL_BUFFSIZE=8388608 
            export NCCL_P2P_NET_CHUNKSIZE=524288
            export NCCL_LAUNCH_MODE=GROUP
            export NCCL_DEBUG=INFO

            LOG_DIR=${BASEDIR}/logs
            TRAINER_DIR=${LOG_DIR}/${CONFIG}${POSTFIX}-eks/trainer-dir
            mkdir -p ${TRAINER_DIR}

            cat << EOF > tf_gpu_fix.py
            import tensorflow as tf
            tf.config.set_visible_devices([], 'GPU')
            import runpy
            runpy.run_module('axlearn.common.launch_trainer_main', run_name='__main__')
            EOF

            python3 tf_gpu_fix.py  \
               --module=text.gpt.c4_trainer \
                --config=${CONFIG} \
                --trainer_dir=${TRAINER_DIR} \
                --data_dir=gs://axlearn-public/tensorflow_datasets \
                --jax_backend=gpu 

        resources:
          limits:
            nvidia.com/gpu: 8
        volumeMounts:
        - name: output
          mountPath: /opt/output
      imagePullSecrets:
      - name: PLACEHOLDER  
      volumes:
      - name: output
        emptyDir: {}
