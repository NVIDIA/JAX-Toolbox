name: Launch workload on GKE with XPK

description: "Launch a JobSet workload on GKE with XPK. Upload artifacts from container to GCS and GitHub Actions."

inputs:
  GITHUB_TOKEN:
    description: 'GitHub artifact registry login token'
    type: string
    required: true
  NVCR_TOKEN:
    description: 'NVCR artifact registry login token'
    type: string
    required: true
  GCP_PROJECT:
    description: 'GCP project ID'
    default: nv-jaxtoolboxgcp-20240925
    type: string
  GKE_CLUSTER:
    description: 'GKE cluster name'
    default: jtb-2025-10-07
    required: false
    type: string
  GCP_REGION:
    description: 'GCP zone of the cluster'
    default: europe-west4
    required: false
    type: string
  CLUSTER_DEVICE: 
    description: 'GPU device type in the cluster'
    default: h100-mega-80gb-8
    required: false
    type: string
  NUM_NODES:
    description: 'Number of nodes to use in JobSet (n.b each a3-megagpu-8g node has 8xGPU)'
    default: 2
    required: false
    type: string
  MAIN_CONTAINER: 
    description: 'Name of the main contianer in an XPK JobSet (fixed)'
    default: gpu-image
    required: false
    type: string
  CONTAINER_OUTPUT_PATH:
    description: 'Output directory for artifacts'
    default: /opt/output
    required: false
    type: string
  GCS_BUCKET:
    description: 'GCS bucket to which CI output artifacts will be uploaded'
    default: jaxtoolbox-ci
    required: false
    type: string
  IMAGE:
    description: 'URI of image to use in JobSet'
    required: false
    default: ghcr.io/nvidia/jax:latest
    type: string
  COMMAND:
    description: 'Command to run in main container on JobSet start up'
    required: false
    default: 'nvidia-smi; free -h;'
    type: string
  EXIT_COMMAND:
    description: 'Command to set exit code'
    required: false
    default: 'exit \$EXIT_CODE'
    type: string
  WORKLOAD_PREFIX:
    description: 'Workload name prefix for XPK, also used to name uploaded artifact'
    required: false
    default: 'xpk'
    type: string
  XPK_VERSION:
    description: 'XPK release tag'
    required: false
    default: 'v1.0.0'
    type: string
  XPK_PYTHON:
    description: 'Python version for XPK'
    required: false
    default: '3.12.10'
    type: string

runs:
  using: 'composite'
  steps:

  - name: Check cluster online
    id: cluster-online
    shell: bash -x -e -u {0}
    run: |

      # check cluster exists
      gcloud container clusters list | grep ${{ inputs.GKE_CLUSTER }} | grep ${{ inputs.GCP_REGION }} | grep RUNNING > /dev/null

      if [[ "$?" == "1" ]]; then
        echo "Cluster ${{ inputs.GKE_CLUSTER }} does not exist"
        echo "proceed=false" >> $GITHUB_OUTPUT
        exit 0
      fi

      # get gpu nodepool name
      GPU_NODEPOOL=$(gcloud container clusters describe ${{ inputs.GKE_CLUSTER }} --region ${{ inputs.GCP_REGION }} | yq -r '.nodePools[].name' | grep -v system)

      # get cluster credentials
      gcloud container clusters get-credentials ${{ inputs.GKE_CLUSTER }} \
        --location=${{ inputs.GCP_REGION }} \
        --dns-endpoint \
        --project=${{ inputs.GCP_PROJECT }} > /dev/null

      # inspect gpu nodes
      GPU_NODES_ONLINE=$(kubectl get nodes -l cloud.google.com/gke-nodepool=${GPU_NODEPOOL} -o json | jq '.items | length >= '${{ inputs.NUM_NODES }})
      echo "proceed=${GPU_NODES_ONLINE}" >> $GITHUB_OUTPUT

  - name: Login to GitHub Container Registry
    if: steps.cluster-online.outputs.proceed == 'true'
    uses: docker/login-action@v3
    with:
      registry: ghcr.io
      username: ${{ github.repository_owner }}
      password: ${{ inputs.GITHUB_TOKEN }}

  - name: Login to nvcr.io Container Registry
    if: steps.cluster-online.outputs.proceed == 'true'
    uses: docker/login-action@v3
    with:
      registry: nvcr.io
      username: $oauthtoken
      password: ${{ inputs.NVCR_TOKEN }}

  - name: K8s GHCR store and delete token
    id: store-token
    if: steps.cluster-online.outputs.proceed == 'true'
    uses: ./.github/actions/store-delete-k8s-ghcr

  - name: Set workload name
    shell: bash -x -e -u {0}
    if: steps.cluster-online.outputs.proceed == 'true'
    run: |
      WORKLOAD="${{ inputs.WORKLOAD_PREFIX }}-${GITHUB_RUN_ID}-${GITHUB_RUN_ATTEMPT}"
      DATE=$(date +'%Y-%m-%d')
      GCS_ARTIFACT_PATH="gs://${{ inputs.GCS_BUCKET }}/${{ inputs.WORKLOAD_PREFIX }}/${DATE}/${WORKLOAD}"

      echo "WORKLOAD=${WORKLOAD}" >> ${GITHUB_ENV}
      echo "DATE=${DATE}" >> ${GITHUB_ENV}
      echo "GCS_ARTIFACT_PATH=${GCS_ARTIFACT_PATH}" >> ${GITHUB_ENV}

  - name: Setup environment
    shell: bash -x -e -u {0}
    if: steps.cluster-online.outputs.proceed == 'true'
    run: |
      mkdir -p ${WORKLOAD}
      uv venv --verbose --python=${{ inputs.XPK_PYTHON }} --directory=${WORKLOAD}
      source ${WORKLOAD}/.venv/bin/activate

      # install xpk
      git clone --depth=1 --branch=${{ inputs.XPK_VERSION }} https://github.com/AI-Hypercomputer/xpk.git ${WORKLOAD}/xpk

      sed 's@pip install -e \.@'$(which uv)' pip install \.@g' -i ${WORKLOAD}/xpk/Makefile
      cd ${WORKLOAD}/xpk && sudo make install; cd -

  - name: Show environment
    shell: bash -x -e -u {0}
    if: steps.cluster-online.outputs.proceed == 'true'
    run: |
      gcloud version
  
      source ${WORKLOAD}/.venv/bin/activate
      python --version
      xpk version
  
  - name: Apply XPK workload create patch
    shell: bash -x -e -u {0}
    if: steps.cluster-online.outputs.proceed == 'true'
    run: |
      PATCH_PATH=.github/gke-workflow/xpk/${{ inputs.XPK_VERSION}}
      ls ${PATCH_PATH}/*.patch | xargs -I {} git apply --unsafe-paths {} --directory ${WORKLOAD}/xpk
  
  - name: Set workload commands
    shell: bash -x -e -u {0}
    if: steps.cluster-online.outputs.proceed == 'true'
    run: |
      # install dependencies for pod artifact upload to GCS
      PRELUDE="
          apt install -y ripgrep > /dev/null;
          curl -LO https://dl.google.com/dl/cloudsdk/channels/rapid/downloads/google-cloud-cli-linux-x86_64.tar.gz;
          tar xf google-cloud-cli-linux-x86_64.tar.gz;
          ./google-cloud-sdk/install.sh --quiet > /dev/null;
          ./google-cloud-sdk/bin/gcloud init;
  
          mkdir -p /usr/share/workload;
          mkdir -p ${{ inputs.CONTAINER_OUTPUT_PATH }};"
  
      # upload pod artifacts to GCS
      POSTLUDE="
          ./google-cloud-sdk/bin/gsutil cp -r ${{ inputs.CONTAINER_OUTPUT_PATH }}/ ${GCS_ARTIFACT_PATH}/node-0\$NODE_RANK;
          ${{ inputs.EXIT_COMMAND }}
      "
  
      CMD="${{ inputs.COMMAND }}"
  
      # set container commands in-line
      CMD=$(echo ${PRELUDE} ${CMD} ${POSTLUDE} | sed 's/\n/\ /g')
      echo "CMD=${CMD}" >> ${GITHUB_ENV}
  
  - name: Create workload on cluster with XPK
    shell: bash -x -e -u {0}
    if: steps.cluster-online.outputs.proceed == 'true'
    run: |
      source ${WORKLOAD}/.venv/bin/activate
      cd ${WORKLOAD}/xpk

      args=(
          --project=${{ inputs.GCP_PROJECT }}
          --cluster=${{ inputs.GKE_CLUSTER }}
          --zone=${{ inputs.GCP_REGION }}
          --workload=${WORKLOAD}
          --docker-image=${{ inputs.IMAGE }}
          --device-type=${{ inputs.CLUSTER_DEVICE }}
          --num-nodes=${{ inputs.NUM_NODES }}
          --num-slices=${{ inputs.NUM_NODES }}
          --priority=high
          --scheduler=gke.io/topology-aware-auto
      )

      version_geq() {
        if [[ $(echo -e "$1\n$2" | sort -V | head -n 1) != "$1" ]]; then
          return 0
        fi
        return 1
      }

      if version_geq "${{ inputs.XPK_VERSION }}" "v0.10.0"; then
          args+=(
              --docker-image-pull-secret=${{ steps.store-token.outputs.token-name }}
              --env="JAX_COORDINATOR_PORT=3389"
              --env="JAX_COORDINATOR_ADDRESS=\$(JOBSET_NAME)-\$(REPLICATED_JOB_NAME)-0-0.\$(JOBSET_NAME):3389"
          )
      fi

      if version_geq "${{ inputs.XPK_VERSION }}" "v1.0.0"; then
        XPK_COMMAND=xpk
      else
        XPK_COMMAND="python xpk.py"
      fi
      ${XPK_COMMAND} workload create ${args[@]} --command="${CMD}"
  
  - name: Wait for JobSet to unsuspend on cluster
    shell: bash -u {0}
    if: steps.cluster-online.outputs.proceed == 'true'
    env:
      POLL_TIMEOUT: 3600
    run: |
      START=$(date +%s)
      JOBSET_ACTIVE=false
      while ! ${JOBSET_ACTIVE}  || [ -z ${JOBSET_ACTIVE} ]; do
        JOBSET_ACTIVE=$(kubectl get jobset -o json | jq -r '.items[] | select(.metadata.name == "'${WORKLOAD}'").status.replicatedJobsStatus[0] | .active == 1')
        NOW=$(date +%s)
        ELAPSED=$(( NOW - START ))
        if (( ELAPSED > POLL_TIMEOUT )) ; then
          echo "Timeout after waiting for JobSet ${WORKLOAD} to become active in cluster ${{ inputs.GKE_CLUSTER }}"
          exit 1
        fi
        echo "Waiting for JobSet ${WORKLOAD} to become active in cluster ${{ inputs.GKE_CLUSTER }}"
        sleep 5
      done
  
      echo "JobSet ${WORKLOAD} has just become active in cluster ${{ inputs.GKE_CLUSTER }}"
  
  - name: Set JobSet Pods names
    shell: bash -u {0}
    if: steps.cluster-online.outputs.proceed == 'true'
    run: |
      echo "JOBSET_PODS=($(kubectl get pods -o json | jq -r '.items[].metadata | select(.labels."jobset.sigs.k8s.io/jobset-name" == "'${WORKLOAD}'") | .name' | tr '\n' ' '))" >> ${GITHUB_ENV}
  
  - name: Wait for JobSet Pod readiness
    shell: bash -u {0}
    if: steps.cluster-online.outputs.proceed == 'true'
    run: |
      for jobset_pod in ${JOBSET_PODS//[()]/}; do
        POD_READY=false
        while [ ${POD_READY} == "false" ] || [ -z ${POD_READY} ]; do
          echo "Waiting for pod ${jobset_pod} in JobSet ${WORKLOAD} to become ready"
          sleep 10
  
          POD_READY=$(kubectl get pod ${jobset_pod} -o json | jq -r '.status.containerStatuses[]? | select(.name == "'${{ inputs.MAIN_CONTAINER }}'").ready')

          if [ ${POD_READY} == "false" ]; then
            POD_ERROR=$(kubectl get pod ${jobset_pod} -o json | jq -r '.status.containerStatuses[]? | select(.name == "'${{ inputs.MAIN_CONTAINER }}'") | .state | ( has("terminated") and (.terminated.reason == "Error" ))')
            if ${POD_ERROR} ; then
              echo "There was an issue starting the JobSet ${WORKLOAD} on ${{ inputs.GKE_CLUSTER }}"
              break
            fi
          fi
  
        done;
      done;
  
  - name: Stream logs from JobSet Pods
    shell: bash -u {0}
    if: steps.cluster-online.outputs.proceed == 'true'
    run: |
      for jobset_pod in ${JOBSET_PODS//[()]/}; do
          kubectl logs --pod-running-timeout=1m -f --prefix=true --timestamps=true -c gpu-image ${jobset_pod} 2>&1 | tee -a ${WORKLOAD}/${jobset_pod}.log &
      done
      wait < <(jobs -p)
  
  - name: Set exit code from JobSet pods logs
    shell: bash -u {0}
    if: steps.cluster-online.outputs.proceed == 'true'
    run: |
      parse_pod_exit_code() {
        local pod=$1
        MAYBE_JOBSET_EXIT_CODE="$(tail -n 1 ${WORKLOAD}/${pod}.log | awk '{ print $3 }' )"
        echo ${MAYBE_JOBSET_EXIT_CODE} | grep -E 'EXIT\_CODE=[0-9]+$' > /dev/null
        
        if [ $? -ne 0 ]; then
          echo "The JobSet ${WORKLOAD} on ${{ inputs.GKE_CLUSTER }} did not complete as expected "
          echo "JOBSET_EXIT_CODE=1" >> ${GITHUB_ENV}
          exit 1
        fi

        echo "Pod ${pod} exited with ${MAYBE_JOBSET_EXIT_CODE}" >&2

        eval "export ${MAYBE_JOBSET_EXIT_CODE}"
        echo ${EXIT_CODE}
      }
      
      ALL_EXIT_CODES=0
      for jobset_pod in ${JOBSET_PODS//[()]/}; do
        POD_EXIT_CODE=$(parse_pod_exit_code ${jobset_pod})
        ALL_EXIT_CODES=$(( ALL_EXIT_CODES + POD_EXIT_CODE ))
      done

      echo "JOBSET_EXIT_CODE=${ALL_EXIT_CODES}" >> ${GITHUB_ENV}
      if [ ${ALL_EXIT_CODES} -gt 0 ]; then
        exit 1
      fi
      exit 0

  - name: Clean up JobSet from cluster
    shell: bash -x -u {0}
    if: steps.cluster-online.outputs.proceed == 'true'
    run: |
      kubectl delete jobset --wait ${WORKLOAD} || echo "JobSet ${WORKLOAD} does not exist in ${{ inputs.GKE_CLUSTER }}"
  
  - name: Download artifacts from GCS to runner
    shell: bash -x -u {0}
    if: steps.cluster-online.outputs.proceed == 'true'
    run: |
      mkdir -p ${WORKLOAD}/output
      gsutil cp -r ${GCS_ARTIFACT_PATH} ${WORKLOAD}/output
      cp ${WORKLOAD}/*.log ${WORKLOAD}/output
  
  - name: Upload artifacts to GitHub Actions from runner
    uses: actions/upload-artifact@v4
    with:
      name: ${{ inputs.WORKLOAD_PREFIX }}
      path: ${{ env.WORKLOAD }}/output/*
  
  - name: Clean up xpk environment from runner
    shell: bash -x -u {0}
    if: ${{ always() }}
    run: |
      sudo rm -rf ${WORKLOAD}

  - name: Generate sitrep
    id: sitrep
    shell: bash -x -e {0}
    if: ${{ always() }}
    run: |
      source .github/workflows/scripts/to_json.sh
      badge_label="${{ matrix.test }}"

      summary="${{ inputs.WORKLOAD_PREFIX }}"
      badge_label="${{ inputs.WORKLOAD_PREFIX }}"

      if [[ -z "${JOBSET_EXIT_CODE}" ]]; then
        badge_color=gray
        outcome=skipped
        summary+=": skipped"
      elif [[ "${JOBSET_EXIT_CODE}" -gt 0 ]]; then 
        badge_color=red
        outcome=failed
        summary+=": fail"
      else
        badge_color=brightgreen
        outcome=success
        summary+=": pass"
      fi

      to_json summary \
              badge_label \
              badge_color \
              outcome | \
      tee sitrep.json

  - name: Upload sitrep to GitHub Actions from runner
    if: ${{ always() }}
    uses: actions/upload-artifact@v4
    with:
      name: ${{ inputs.WORKLOAD_PREFIX }}-sitrep
      path: |
        sitrep.json
