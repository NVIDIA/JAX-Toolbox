#!/bin/bash
#SBATCH -A example              # slurm account
#SBATCH -p partition            # slurm partition name
#SBATCH -N 8                    # number of nodes
#SBATCH -t 00:30:00             # wall time
#SBATCH -J "paxml:test"         # job name
#SBATCH --exclusive             # exclusive node access
#SBATCH --mem=0                 # all mem avail
#SBATCH --ntasks-per-node=8     # n tasks per machine (one task per gpu)
#SBATCH --overcommit            
#SBATCH --dependency=singleton  # only run one instance at a time
set -eux

# coding=utf-8
# Copyright 2022 The Pax Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# File system and volume glue code
#-------------------------------------------------------------------------------
# << CHANGE ! >>
CONTAINER="${CONTAINER:-nvcr.io/nvidia/jax:23.10-paxml-py3}"

# << CHANGE ! >>
BASE_WORKSPACE_DIR=${BASE_WORKSPACE_DIR} ## location to write logs and checkpoints to
PAXML_DIR=${PAXML_DIR:-/opt/paxml}
ENABLE_TE=${ENABLE_TE:-1}
ENABLE_FP8=${ENABLE_FP8:-0}

# Default env variables for paths required by pax training scripts
WORKSPACE_DIR=/opt/paxml/workspace

# Add the pax/JAX specific mounts
MOUNTS="--container-mounts=$BASE_WORKSPACE_DIR:$WORKSPACE_DIR"

# Make directories that may not exist
mkdir -p $BASE_WORKSPACE_DIR

EXPORTS="--export=ALL"
#-------------------------------------------------------------------------------

CONFIG=${CONFIG:-"Synthetic126M"}
OUTPUT_DIR=${OUTPUT_DIR:-"output"}
PREC=${PREC}
GPUS_PER_NODE=${GPUS_PER_NODE}
PERCORE_BATCH_SIZE=${PERCORE_BATCH_SIZE}
LOG_DIR_LOCAL=${LOG_DIR_LOCAL}

if [[ -z "${BASE_SCRIPT:-}" ]]; then
  export BASE_SCRIPT="${PAXML_DIR}/paxml/contrib/gpu/scripts_gpu/benchmark_gpt_multinode.sh"
  echo "Using default BASE_SCRIPT=$BASE_SCRIPT"
else
  export BASE_SCRIPT="${WORKSPACE_DIR}/${BASE_SCRIPT}"
  echo "Using custom BASE_SCRIPT=$BASE_SCRIPT"
fi

cmd="$(cat <<EOF
echo "*******STARTING********"
cd ${PAXML_DIR}
nvidia-smi
ENABLE_TE=$ENABLE_TE ENABLE_FP8=$ENABLE_FP8 bash $BASE_SCRIPT $CONFIG $PREC $GPUS_PER_NODE $PERCORE_BATCH_SIZE ${WORKSPACE_DIR}/${LOG_DIR_LOCAL}
EOF
)"

# create run specific output directory for ease of analysis
DIR=${BASE_WORKSPACE_DIR}/${OUTPUT_DIR}
mkdir -p $DIR

# redirect both stdout and stderr in the same file for ease of analysis
OUTFILE="${DIR}/output-%j-%n-%t.txt"

echo $cmd
srun -o $OUTFILE -e $OUTFILE --container-image="$CONTAINER" $MOUNTS $EXPORTS bash -e -c "${cmd}"
set +x

