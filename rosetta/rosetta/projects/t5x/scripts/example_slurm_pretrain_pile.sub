#!/bin/bash
#SBATCH -A example              # slurm account
#SBATCH -p partition            # slurm partition name
#SBATCH -N 1                    # number of nodes
#SBATCH -t 04:00:00             # wall time
#SBATCH -J "t5x:train"          # slurm job name
#SBATCH --exclusive             # exclusive node access
#SBATCH --mem=0                 # all mem avail
#SBATCH --mail-type=FAIL        # only send email on failure
#SBATCH --overcommit            
#SBATCH --dependency=singleton  # tells slurm to run only one job with the same job name at a time
set -eoux

# File system and volume glue code
#-------------------------------------------------------------------------------

# << CHANGE ! >>
CONTAINER="${CONTAINER:-ghcr.io/nvidia/t5x:latest-verified}" # Add link to your built container

# << CHANGE ! >>
# BASE_TFDS_DATA_DIR and DATASET_MAP are mutually exclusive
BASE_TFDS_DATA_DIR=${BASE_TFDS_DATA_DIR:-}         # path to tfds data directory
DATASET_MAP=${DATASET_MAP:-}                       # Colon-sep mapping of local dataset dir to name of dataset dir within container. If multiple datasets, separate by comma Format expected: "local_dir1:dataset_name1(,local_dir2:dataset_name2,...)". Example: "/mnt/the_pile:the_pile,/mnt/foobar/squad:squad"
BASE_T5X_OUTPUTS_DIR="${BASE_T5X_OUTPUTS_DIR}"     # path to slurm output logs
BASE_T5X_WORKSPACE_DIR="${BASE_T5X_WORKSPACE_DIR}" # path to where training outputs will be dumped
T5X_DIR=${T5X_DIR:-/opt/t5x}

# Default env variables for paths required by t5x training scripts
TFDS_DATA_DIR=/t5x_home/datasets
T5X_WORKSPACE_DIR=/t5x_home/workspace

# Add the T5x/JAX specific mounts
MOUNTS="--container-mounts=$BASE_T5X_WORKSPACE_DIR:$T5X_WORKSPACE_DIR"
if [[ -z "$BASE_TFDS_DATA_DIR" && -z "$DATASET_MAP" ]]; then
  echo "BASE_TFDS_DATA_DIR and DATASET_MAP cannot both be empty"
  exit 1
elif [[ -n "$BASE_TFDS_DATA_DIR" && -n "$DATASET_MAP" ]]; then
  echo "BASE_TFDS_DATA_DIR=$BASE_TFDS_DATA_DIR and DATASET_MAP=$DATASET_MAP cannot both be specified"
  exit 1
elif [[ -n "$BASE_TFDS_DATA_DIR" ]]; then
  MOUNTS+=",$BASE_TFDS_DATA_DIR:$TFDS_DATA_DIR"
else # [[ -n "$DATASET_MAP" ]]
  # Converts /local/path/to/squad:squad to /local/poath/to/squad:$TFDS_DATA_DIR/squad
  MOUNTS+=",${DATASET_MAP//:/:$TFDS_DATA_DIR/}"
fi

# Make directories that may not exist
mkdir -p $BASE_T5X_OUTPUTS_DIR $BASE_T5X_WORKSPACE_DIR
EXPORTS="--export=ALL"
#-------------------------------------------------------------------------------

# Command line arguments needed by the underlying scripts
PREC=${PREC:="bfloat16"}
T5_SIZE=${T5_SIZE:="large"}
BSIZE_PER_GPU=${BSIZE_PER_GPU:=32}
ENC_SL=${ENC_SL:=512}
DEC_SL=${DEC_SL:=128}
TRAIN_STEPS=${TRAIN_STEPS:=500}
NUM_MICROBATCHES=${NUM_MICROBATCHES:=1}
ENABLE_FP8=${ENABLE_FP8:=1} # Uses TransformerEngine FP8
TP_SIZE=${TP_SIZE:=1}
TRANSPOSE_BS=${TRANSPOSE_BS:=1} # An optimization for GPUs
MODEL_DIR=${MODEL_DIR}
FUSE_QKV=${FUSE_QKV:=1} # Used with TransformerEngine
PACK=${PACK:=0} # Not supported with TransformerEngine

export GPUS_PER_NODE=${1:-8}
export BASE_SCRIPT=${2:-"${T5X_DIR}/t5x/contrib/gpu/scripts_gpu/multiprocess_pretrain_pile.sh"}
export WITH_MP=1

NUM_GPUS=$(( GPUS_PER_NODE * SLURM_STEP_NUM_NODES ))

# << CHANGE ! >>
# You can add binding to the command below with the following line (after nvidia-smi). Remove the '&&' on the next bash line.
# && bash <<path_to_bind_script>>/bind.sh --cpu=exclusive --ib=single -- \
cmd="$(cat <<EOF
cd ${T5X_DIR}
env
nvidia-smi
T5X_DIR=${T5X_DIR} T5X_WORKSPACE_DIR=${T5X_WORKSPACE_DIR} TFDS_DATA_DIR=${TFDS_DATA_DIR} MODEL_DIR=${MODEL_DIR} PREC=${PREC} T5_SIZE=${T5_SIZE} BSIZE_PER_GPU=${BSIZE_PER_GPU} ENC_SL=${ENC_SL} DEC_SL=${DEC_SL} TRAIN_STEPS=${TRAIN_STEPS} NUM_MICROBATCHES=${NUM_MICROBATCHES} ENABLE_FP8=${ENABLE_FP8} TP_SIZE=${TP_SIZE} TRANSPOSE_BS=${TRANSPOSE_BS} FUSE_QKV=${FUSE_QKV} PACK=${PACK} bash $BASE_SCRIPT
EOF
)"

# create run specific output directory for ease of analysis
FOLDER="${BASE_T5X_OUTPUTS_DIR}/multinode/PRETRAIN-${T5_SIZE}-${PREC}-N${SLURM_STEP_NUM_NODES}-n${NUM_GPUS}-Step${TRAIN_STEPS}-BS${BSIZE_PER_GPU}-MBS${NUM_MICROBATCHES}-SL${ENC_SL}_${DEC_SL}-TP${TP_SIZE}-FP8${ENABLE_FP8}"
mkdir -p ${FOLDER}

# redirect both stdout and stderr in the same file for ease of analysis
OUTFILE="${FOLDER}/output-%j-%t.txt"

echo $cmd
# --no-container-mount-home: local python packages can interfere with the packages pre-installed
srun --no-container-mount-home --ntasks-per-node=${GPUS_PER_NODE} -o $OUTFILE -e $OUTFILE --container-image="$CONTAINER" $MOUNTS $EXPORTS bash -c "${cmd}"
set +x
